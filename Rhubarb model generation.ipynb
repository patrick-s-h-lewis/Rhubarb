{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random sentence generation to test model hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lewisp123/miniconda2/envs/Fruitbowl/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import sys, traceback\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(topic_no,total_topics,alphabet_length):\n",
    "    return(topic_no*alphabet_length/(1.0*total_topics))\n",
    "\n",
    "def make_sentence(alphabet_length,mean,std,sentence_len):\n",
    "    sentence=[]\n",
    "    for i in range(sentence_len):\n",
    "        letter=int(round(random.gauss(mean,std),0))\n",
    "        sentence.append(letter)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphabet_length=100\n",
    "topics = 50\n",
    "distros = []\n",
    "for t in range(1,topics+1):\n",
    "    distros.append((mean(t,topics,alphabet_length),random.uniform(.75,(1.75*alphabet_length)/(1.*topics))))\n",
    "    \n",
    "    \n",
    "sent_lens = []\n",
    "sents2=[]\n",
    "sent3=[]\n",
    "for i in range(topics):\n",
    "    sent = make_sentence(alphabet_length,distros[i][0],distros[i][1],100000)\n",
    "    sent_lens.append(Counter(sent))\n",
    "    sents2.append(sent)\n",
    "    sent3+=sent\n",
    "    plottable=Counter(sent).most_common()\n",
    "    plottable.sort()\n",
    "    plt.plot(zip(*plottable)[0],zip(*plottable)[1])\n",
    "plt.show()\n",
    "max_word = max(map(lambda x: max(x),sents2))\n",
    "min_word = min(map(lambda x: min(x),sents2))\n",
    "plottable=Counter(sent3).most_common()\n",
    "plottable.sort()\n",
    "plt.plot(zip(*plottable)[0],zip(*plottable)[1])\n",
    "plt.show()\n",
    "print(max_word)\n",
    "print(min_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doc_len_distro(x):\n",
    "    return 5.991524457330881*x**2*math.exp(-0.00034375*x**2)\n",
    "\n",
    "def generate_sentence_lens(sample_size):\n",
    "    max_len = 200\n",
    "    increment = 5\n",
    "    samples = map(lambda x: (x,doc_len_distro(x)),range(0,205,5))\n",
    "    s_samples = sum(zip(*samples)[1])\n",
    "    scale = sample_size/s_samples\n",
    "    return map(lambda x: (x[0],int(round(scale*x[1],0))),samples)\n",
    "\n",
    "def generate_sentences(alphabet_len,mean,std,samples):\n",
    "    sentences = []\n",
    "    for ind in range(len(samples)):\n",
    "        for sent_no in range(samples[ind][1]):\n",
    "            sentence = make_sentence(alphabet_len,mean,std,samples[ind][0])\n",
    "            sentences.append(sentence)\n",
    "    maxi = max(map(lambda x: max(x),sentences))\n",
    "    mini = min(map(lambda x: min(x),sentences))\n",
    "    return mini,maxi,sentences \n",
    "\n",
    "def generate_corpus(alphabet_len,sample_size,topics,filename):\n",
    "    distros = []\n",
    "    for t in range(1,topics+1):\n",
    "        distros.append((\n",
    "                mean(t,topics,alphabet_len),\n",
    "                random.uniform(.75,(1.75*alphabet_len)/(1.*topics))\n",
    "            ))\n",
    "    \n",
    "    samples = generate_sentence_lens(sample_size)\n",
    "    corpus=[]\n",
    "    global_mini = 0\n",
    "    global_maxi = alphabet_len\n",
    "    with open(filename,'a') as f:\n",
    "        writer = csv.writer(f, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for me,std in distros:\n",
    "            mini,maxi,sentences = generate_sentences(alphabet_len,me,std,samples)\n",
    "            if mini<global_mini: global_mini=mini\n",
    "            if maxi>global_maxi: global_maxi=maxi\n",
    "            for sent in sentences:\n",
    "                writer.writerow(sent)\n",
    "    print('unique words: '+str(-global_mini+global_maxi))\n",
    "    print('small_word: '+str(global_mini))\n",
    "    return corpus,global_mini,global_maxi\n",
    "\n",
    "def rescale_corpus(filename,mini):\n",
    "    with open(filename,'r') as f1:\n",
    "        with open(filename.split('.')[0]+'scaled.csv','a') as f2:\n",
    "            with open(filename.split('.')[0]+'natural.txt','a') as f3:\n",
    "                writer = csv.writer(f2, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                reader = csv.reader(f1,delimiter=',')\n",
    "                for row in reader:\n",
    "                    wr = map(lambda x: int(x)-mini,row)\n",
    "                    writer.writerow(wr)\n",
    "                    f3.write(' '.join([str(i)for i in wr])+'\\n')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words: 124\n",
      "small_word: -8\n"
     ]
    }
   ],
   "source": [
    "c,mi,ma = generate_corpus(100,10000,50,'harder.csv')\n",
    "rescale_corpus('harder.csv',mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=sent_lens[0].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-12, 2),\n",
       " (-11, 2),\n",
       " (-10, 19),\n",
       " (-9, 29),\n",
       " (-8, 93),\n",
       " (-7, 275),\n",
       " (-6, 580),\n",
       " (-5, 1180),\n",
       " (-4, 2189),\n",
       " (-3, 3826),\n",
       " (-2, 5804),\n",
       " (-1, 7942),\n",
       " (0, 10055),\n",
       " (1, 11700),\n",
       " (2, 12321),\n",
       " (3, 11666),\n",
       " (4, 10247),\n",
       " (5, 7978),\n",
       " (6, 5778),\n",
       " (7, 3813),\n",
       " (8, 2300),\n",
       " (9, 1199),\n",
       " (10, 558),\n",
       " (11, 286),\n",
       " (12, 96),\n",
       " (13, 39),\n",
       " (14, 16),\n",
       " (15, 6),\n",
       " (16, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

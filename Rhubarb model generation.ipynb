{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random sentence generation to test model hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "import sys, traceback\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(topic_no,total_topics,alphabet_length):\n",
    "    return(topic_no*alphabet_length/(1.0*total_topics))\n",
    "\n",
    "def make_sentence(alphabet_length,mean,std,sentence_len):\n",
    "    sentence=[]\n",
    "    for i in range(sentence_len):\n",
    "        letter=int(round(random.gauss(mean,std),0))\n",
    "        #if letter<0: letter+=alphabet_length\n",
    "        #if letter>alphabet_length:letter-=alphabet_length\n",
    "        sentence.append(letter)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.0\n",
      "-42.0\n"
     ]
    }
   ],
   "source": [
    "alphabet_length=100\n",
    "topics = 10\n",
    "distros = []\n",
    "for t in range(1,topics+1):\n",
    "    distros.append((mean(t,topics,alphabet_length),random.uniform(.75,(1.75*alphabet_length)/(1.*topics))))\n",
    "    \n",
    "    \n",
    "sent_lens = []\n",
    "sents2=[]\n",
    "for i in range(topics):\n",
    "    sent = make_sentence(alphabet_length,distros[i][0],distros[i][1],100000)\n",
    "    sent_lens.append(Counter(sent))\n",
    "    sents2.append(sent)\n",
    "    plt.plot(sent_lens[i].keys(),sent_lens[i].values(),'o')\n",
    "    #plt.axis([-5, 15,0,27000])\n",
    "max_word = max(map(lambda x: max(x),sents2))\n",
    "min_word = min(map(lambda x: min(x),sents2))\n",
    "plt.show()\n",
    "print(max_word)\n",
    "print(min_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doc_len_distro(x):\n",
    "    return 5.991524457330881*x**2*math.exp(-0.00034375*x**2)\n",
    "\n",
    "def generate_sentence_lens(sample_size):\n",
    "    max_len = 200\n",
    "    increment = 5\n",
    "    samples = map(lambda x: (x,doc_len_distro(x)),range(0,205,5))\n",
    "    s_samples = sum(zip(*samples)[1])\n",
    "    scale = sample_size/s_samples\n",
    "    return map(lambda x: (x[0],int(round(scale*x[1],0))),samples)\n",
    "\n",
    "def generate_sentences(alphabet_len,mean,std,samples):\n",
    "    sentences = []\n",
    "    for ind in range(len(samples)):\n",
    "        for sent_no in range(samples[ind][1]):\n",
    "            sentence = make_sentence(alphabet_len,mean,std,samples[ind][0])\n",
    "            sentences.append(sentence)\n",
    "    maxi = max(map(lambda x: max(x),sentences))\n",
    "    mini = min(map(lambda x: min(x),sentences))\n",
    "    return mini,maxi,sentences \n",
    "\n",
    "def generate_corpus(alphabet_len,sample_size,topics):\n",
    "    distros = []\n",
    "    for t in range(1,topics+1):\n",
    "        distros.append((\n",
    "                mean(t,topics,alphabet_len),\n",
    "                random.uniform(.75,(1.75*alphabet_len)/(1.*topics))\n",
    "            ))\n",
    "    \n",
    "    samples = generate_sentence_lens(sample_size)\n",
    "    corpus=[]\n",
    "    global_mini = 0\n",
    "    global_maxi = alphabet_len\n",
    "    with open('corp.csv','a') as f:\n",
    "        writer = csv.writer(f, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for me,std in distros:\n",
    "            mini,maxi,sentences = generate_sentences(alphabet_len,me,std,samples)\n",
    "            if mini<global_mini: global_mini=mini\n",
    "            if maxi>global_maxi: global_maxi=maxi\n",
    "            for sent in sentences:\n",
    "                writer.writerow(sent)\n",
    "    print('unique words: '+str(-global_mini+global_maxi))\n",
    "    print('small_word: '+str(global_mini))\n",
    "    return corpus\n",
    "\n",
    "def rescale_corpus(filename,mini):\n",
    "    with open(filename,'r') as f1:\n",
    "        with open(filename.split('.')[0]+'scaled.csv','a') as f2:\n",
    "            with open(filename.split('.')[0]+'natural.txt','a') as f3:\n",
    "                writer = csv.writer(f2, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                reader = csv.reader(f1,delimiter=',')\n",
    "                for row in reader:\n",
    "                    wr = map(lambda x: int(x)-mini,row)\n",
    "                    writer.writerow(wr)\n",
    "                    f3.write(' '.join([str(i)for i in wr])+'\\n')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words: 238\n",
      "small_word: -59\n"
     ]
    }
   ],
   "source": [
    "c = generate_corpus(100,10000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rescale_corpus('corp.csv',-59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bib=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected string, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-7c479dd9f896>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected string, int found"
     ]
    }
   ],
   "source": [
    "' '.join([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

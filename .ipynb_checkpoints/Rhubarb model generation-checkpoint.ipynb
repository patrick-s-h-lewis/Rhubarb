{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random sentence generation to test model hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "import sys, traceback\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(topic_no,total_topics,alphabet_length):\n",
    "    return(topic_no*alphabet_length/(1.0*total_topics))\n",
    "\n",
    "def make_sentence(alphabet_length,mean,std,sentence_len):\n",
    "    sentence=[]\n",
    "    for i in range(sentence_len):\n",
    "        letter=round(random.gauss(mean,std),0)\n",
    "        #if letter<0: letter+=alphabet_length\n",
    "        #if letter>alphabet_length:letter-=alphabet_length\n",
    "        sentence.append(letter)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.0\n",
      "-42.0\n"
     ]
    }
   ],
   "source": [
    "alphabet_length=100\n",
    "topics = 10\n",
    "distros = []\n",
    "for t in range(1,topics+1):\n",
    "    distros.append((mean(t,topics,alphabet_length),random.uniform(.75,(1.75*alphabet_length)/(1.*topics))))\n",
    "    \n",
    "    \n",
    "sent_lens = []\n",
    "sents2=[]\n",
    "for i in range(topics):\n",
    "    sent = make_sentence(alphabet_length,distros[i][0],distros[i][1],100000)\n",
    "    sent_lens.append(Counter(sent))\n",
    "    sents2.append(sent)\n",
    "    plt.plot(sent_lens[i].keys(),sent_lens[i].values(),'o')\n",
    "    #plt.axis([-5, 15,0,27000])\n",
    "max_word = max(map(lambda x: max(x),sents2))\n",
    "min_word = min(map(lambda x: min(x),sents2))\n",
    "plt.show()\n",
    "print(max_word)\n",
    "print(min_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doc_len_distro(x):\n",
    "    return 5.991524457330881*x**2*math.exp(-0.00034375*x**2)\n",
    "\n",
    "def generate_sentence_lens(sample_size):\n",
    "    max_len = 200\n",
    "    increment = 5\n",
    "    samples = map(lambda x: (x,doc_len_distro(x)),range(0,205,5))\n",
    "    s_samples = sum(zip(*samples)[1])\n",
    "    scale = sample_size/s_samples\n",
    "    return map(lambda x: (x[0],int(round(scale*x[1],0))),samples)\n",
    "\n",
    "def generate_sentences(alphabet_len,mean,std,samples):\n",
    "    sentences = []\n",
    "    for ind in range(len(samples)):\n",
    "        for sent_no in range(samples[ind][1]):\n",
    "            sentence = make_sentence(alphabet_len,mean,std,samples[ind][0])\n",
    "            sentences.append(sentence)\n",
    "    maxi = max(map(lambda x: max(x),sentences))\n",
    "    mini = min(map(lambda x: min(x),sentences))\n",
    "    return mini,maxi,sentences \n",
    "\n",
    "def generate_corpus(alphabet_len,sample_size,topics):\n",
    "    distros = []\n",
    "    for t in range(1,topics+1):\n",
    "        distros.append((\n",
    "                mean(t,topics,alphabet_len),\n",
    "                random.uniform(.75,(1.75*alphabet_len)/(1.*topics))\n",
    "            ))\n",
    "    \n",
    "    samples = generate_sentence_lens(sample_size)\n",
    "    corpus=[]\n",
    "    global_mini = 0\n",
    "    global_maxi = alphabet_len\n",
    "    with open('corp.csv','a') as f:\n",
    "        writer = csv.writer(f, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for me,std in distros:\n",
    "            mini,maxi,sentences = generate_sentences(alphabet_len,me,std,samples)\n",
    "            if mini<global_mini: global_mini=mini\n",
    "            if maxi>global_maxi: global_maxi=maxi\n",
    "            for sent in sentences:\n",
    "                writer.writerow(sent)\n",
    "    print('unique words: '+str(-global_mini+global_maxi))\n",
    "    print('small_word: '+str(global_mini))\n",
    "    return corpus\n",
    "\n",
    "def rescale_corpus(filename):\n",
    "    with open(filename,'r') as f1:\n",
    "        reader = csv.reader(f1,delimiter=',')\n",
    "        for row in reader:\n",
    "            print(type(row))\n",
    "            print(row[0])\n",
    "            print('hi'+bib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-81b88de4d5a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-6d663c1fe61a>\u001b[0m in \u001b[0;36mgenerate_corpus\u001b[1;34m(alphabet_len, sample_size, topics)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mquotechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQUOTE_MINIMAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mme\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdistros\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mmini\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphabet_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mme\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmini\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mglobal_mini\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mglobal_mini\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmini\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmaxi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mglobal_maxi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mglobal_maxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-6d663c1fe61a>\u001b[0m in \u001b[0;36mgenerate_sentences\u001b[1;34m(alphabet_len, mean, std, samples)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msent_no\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphabet_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmaxi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-5cfd000f61d4>\u001b[0m in \u001b[0;36mmake_sentence\u001b[1;34m(alphabet_length, mean, std, sentence_len)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m#if letter<0: letter+=alphabet_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#if letter>alphabet_length:letter-=alphabet_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = generate_corpus(100,10000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c6494b964a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "rescale_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bib=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
